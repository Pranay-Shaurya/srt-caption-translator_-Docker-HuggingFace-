{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf40065-4b87-416b-b529-def6fbe8c435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-base and revision a9723ea (https://huggingface.co/google-t5/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation_en_to_fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4526e648-7a92-436f-b9d4-280aef3c06c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 11:54:19.267262: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xaaab30a25980 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2025-05-31 11:54:19.267520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2025-05-31 11:54:19.342150: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-05-31 11:54:19.550039: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-05-31 11:54:19.557305: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n"
     ]
    }
   ],
   "source": [
    "fr = translator(\"My name is Pranay and I am a Programmer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a588df56-e8d0-44e3-84ea-df1dfe0972e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je m'appelle Pranay et je suis programmateur\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr[0]['translation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f318ad6-071e-4a92-8d36-61ffbfd77568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysrt\n",
    "\n",
    "subs = pysrt.open(\"captions_english.srt\")\n",
    "\n",
    "for i in subs:\n",
    "    fr_text = translator(i.text)[0]['translation_text']\n",
    "    i.text = fr_text\n",
    "\n",
    "subs.save(\"captions_french.srt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aebf6655-bbad-4058-942f-f823f7171cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: pysrt\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
